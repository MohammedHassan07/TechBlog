-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Oct 15, 2023 at 05:14 PM
-- Server version: 10.4.28-MariaDB
-- PHP Version: 8.2.4

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `blogsdb`
--

-- --------------------------------------------------------

--
-- Table structure for table `blogs`
--

CREATE TABLE `blogs` (
  `Id` int(11) NOT NULL,
  `blogTitle` text DEFAULT NULL,
  `BlogContent` text DEFAULT NULL,
  `ImgURL` text DEFAULT NULL,
  `smallPara` varchar(30) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `blogs`
--

INSERT INTO `blogs` (`Id`, `blogTitle`, `BlogContent`, `ImgURL`, `smallPara`) VALUES
(1, 'Trends in IT Industry', 'Information technology (IT) is a set of related fields that encompass computer systems, software, programming languages and data and information processing and storage.[1] IT forms part of information and communications technology (ICT).[2] An information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users, and an IT project usually refers to the commissioning and implementation of an IT system.[3]Although humans have been storing, retrieving, manipulating, and communicating information since the earliest writing systems were developed,[4] the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that \"the new technology does not yet have a single established name. We shall call it information technology (IT).\"[5] Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.', 'https://media.licdn.com/dms/image/D5612AQETyzAUfT8utA/article-cover_image-shrink_600_2000/0/1696577699642?e=2147483647&v=beta&t=oAxM9Kj2rDl4_jbXhvvSqz2ORdLYsusNyYJuh9Ufg30', 'Emerging Trends in IT Industry'),
(2, 'Data Science', 'Data science is the study of data to extract meaningful insights for business. It is a multidisciplinary approach that combines principles and practices from the fields of mathematics, statistics, artificial intelligence, and computer engineering to analyze large amounts of data. This analysis helps data scientists to ask and answer questions like what happened, why it happened, what will happen, and what can be done with the results.\nWhile the term data science is not new, the meanings and connotations have changed over time. The word first appeared in the ’60s as an alternative name for statistics. In the late ’90s, computer science professionals formalized the term. A proposed definition for data science saw it as a separate field with three aspects: data design, collection, and analysis. It still took another decade for the term to be used outside of academia. \n\nArtificial intelligence and machine learning innovations have made data processing faster and more efficient. Industry demand has created an ecosystem of courses, degrees, and job positions within the field of data science. Because of the cross-functional skillset and expertise required, data science shows strong projected growth over the coming decades.\n', 'https://iimk.emeritus.org/iimk-advanced-data-science-for-managers/images/main-banner-new.jpg', 'Make a career in Data Science'),
(3, 'About Python', 'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.[32]\n\nPython is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[33][34]\n\nGuido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.[35] Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.[36]\n\nPython consistently ranks as one of the most popular programming languages.Python was conceived in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[11] Its implementation began in December 1989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\'s \"benevolent dictator for life\", a title the Python community bestowed upon him to reflect his long-term commitment as the project\'s chief decision-maker.[44] In January 2019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\n\nPython 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python 3.0, released on 3 December 2008, with many of its major features backported to Python 2.6.x[48] and 2.7.x. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.[49]\n\nPython 2.7\'s end-of-life was initially set for 2015, then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.[50][51] No further security patches or other improvements will be released for it.[52][53] Currently only 3.8 and later are supported (2023 security issues were fixed in e.g. 3.7.17, the final 3.7.x release[54]).\n\nIn 2021 (and again twice in 2022), security updates were expedited; since all Python versions were insecure (including 2.7[55]) because of security issues leading to possible remote code execution[56] and web-cache poisoning.[57] In 2022, Python 3.10.4 and 3.9.12 were expedited[58] and 3.8.13, because of many security issues.[59] When Python 3.9.13 was released in May 2022, it was announced that the 3.9 series (joining the older series 3.8 and 3.7) would only receive security fixes in the future.[60] On 7 September 2022, four new releases were made due to a potential denial-of-service attack: 3.10.7, 3.9.14, 3.8.14, and 3.7.14.[61][62]\n\nAs of October 2023, Python 3.12 is the stable release, and 3.12 and 3.11 are the only versions with active (as opposed to just security) support. Notable changes in 3.11 from 3.10 include increased program execution speed and improved error reporting.[63]\n\nPython 3.12 adds syntax (and in fact every Python since at least 3.5 adds some syntax) to the language, the new (soft) keyword type (recent releases have added a lot of typing support e.g. new type union operator in 3.10), and 3.11 for exception handling, and 3.10 the match and case (soft) keywords, for structural pattern matching statements. Python 3.12 also drops outdated modules and functionality, and future versions will too, see below in Development section.\n\nPython 3.11 claims to be between 10 and 60% faster than Python 3.10, and Python 3.12 adds another 5% on top of that. It also has improved error messages, and many other changes.\n\nSince 27 June 2023, Python 3.8 is the oldest supported version of Python (albeit in the \'security support\' phase), due to Python 3.7 reaching end-of-life.\nPython\'s statements include:\n\n    The assignment statement, using a single equals sign =\n    The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if)\n    The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block\n    The while statement, which executes a block of code as long as its condition is true\n    The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses (or new syntax except* in Python 3.11 for exception groups[86]); it also ensures that clean-up code in a finally block is always run regardless of how the block exits\n    The raise statement, used to raise a specified exception or re-raise a caught exception\n    The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming\n    The def statement, which defines a function or method\n    The with statement, which encloses a code block within a context manager (for example, acquiring a lock before it is run, then releasing the lock; or opening and closing a file), allowing resource-acquisition-is-initialization (RAII)-like behavior and replacing a common try/finally idiom[87]\n    The break statement, which exits a loop\n    The continue statement, which skips the rest of the current iteration and continues with the next\n    The del statement, which removes a variable—deleting the reference from the name to the value, and producing an error if the variable is referred to before it is redefined\n    The pass statement, serving as a NOP, syntactically needed to create an empty code block\n    The assert statement, used in debugging to check for conditions that should apply\n    The yield statement, which returns a value from a generator function (and also an operator); used to implement coroutines\n    The return statement, used to return a value from a function\n    The import and from statements, used to import modules whose functions or variables can be used in the current program\n\nThe assignment statement (=) binds a name as a reference to a separate, dynamically allocated object. Variables may subsequently be rebound at any time to any object. In Python, a variable name is a generic reference holder without a fixed data type; however, it always refers to some object with a type. This is called dynamic typing—in contrast to statically-typed languages, where each variable may contain only a value of a certain type.\n\nPython does not support tail call optimization or first-class continuations, and, according to Van Rossum, it never will.[88][89] However, better support for coroutine-like functionality is provided by extending Python\'s generators.[90] Before 2.5, generators were lazy iterators; data was passed unidirectionally out of the generator. From Python 2.5 on, it is possible to pass data back into a generator function; and from version 3.3, it can be passed through multiple stack levels.[91]\n\n\n', 'https://static.miraheze.org/r2wiki/thumb/3/3c/Python1.png/300px-Python1.png', 'All about Python Programming'),
(4, 'Software Testing', 'Software testing is the act of examining the artifacts and the behavior of the software under test by validation and verification. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include, but are not necessarily limited to:\n\n    analyzing the product requirements for completeness and correctness in various contexts like industry perspective, business perspective, feasibility and viability of implementation, usability, performance, security, infrastructure considerations, etc.\n    reviewing the product architecture and the overall design of the product\n    working with product developers on improvement in coding techniques, design patterns, tests that can be written as part of code based on various techniques like boundary conditions, etc.\n    executing a program or application with the intent of examining behavior\n    reviewing the deployment infrastructure and associated scripts and automation\n    take part in production activities by using monitoring and observability techniques\n\nSoftware testing can provide objective, independent information about the quality of software and the risk of its failure to users or sponsors.[1]\n\nSoftware testing can determine the correctness of software under the assumption of some specific hypotheses (see the hierarchy of testing difficulty below), but testing cannot identify all the failures within the software.[2] Instead, it furnishes a criticism or comparison that compares the state and behavior of the product against test oracles — principles or mechanisms by which someone might recognize a problem. These oracles may include (but are not limited to) specifications, contracts,[3] comparable products, past versions of the same product, inferences about intended or expected purpose, user or customer expectations, relevant standards, applicable laws, or other criteria.\n\nA primary purpose of testing is to detect software failures so that defects may be discovered and corrected. Testing cannot establish that a product functions properly under all conditions, but only that it does not function properly under specific conditions.[4] The scope of software testing may include the examination of code as well as the execution of that code in various environments and conditions as well as examining the aspects of code: does it do what it is supposed to do and do what it needs to do. In the current culture of software development, a testing organization may be separate from the development team. There are various roles for testing team members. Information derived from software testing may be used to correct the process by which software is developed.[5]: 41–43 \n\nEvery software product has a target audience. For example, the audience for video game software is completely different that for banking software. Therefore, when an organization develops or otherwise invests in a software product, it can assess whether the software product will be acceptable to its end users, its target audience, its purchasers, and other stakeholders. Software testing assists in making this assessment.There are many approaches available in software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas executing programmed code with a given set of test cases is referred to as dynamic testing.[15][16]\n\nStatic testing is often implicit, like proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules.[15][16] Typical techniques for these are either using stubs/drivers or execution from a debugger environment.[16]\n\nStatic testing involves verification, whereas dynamic testing also involves validation.[16]\n\nPassive testing means verifying the system behavior without any interaction with the software product. Contrary to active testing, testers do not provide any test data but look at system logs and traces. They mine for patterns and specific behavior in order to make some kind of decisions.[17] This is related to offline runtime verification and log analysis.There are many approaches available in software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas executing programmed code with a given set of test cases is referred to as dynamic testing.[15][16]\n\nStatic testing is often implicit, like proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules.[15][16] Typical techniques for these are either using stubs/drivers or execution from a debugger environment.[16]\n\nStatic testing involves verification, whereas dynamic testing also involves validation.[16]\n\nPassive testing means verifying the system behavior without any interaction with the software product. Contrary to active testing, testers do not provide any test data but look at system logs and traces. They mine for patterns and specific behavior in order to make some kind of decisions.[17] This is related to offline runtime verification and log analysis.\nThere are many approaches available in software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas executing programmed code with a given set of test cases is referred to as dynamic testing.[15][16]\n\nStatic testing is often implicit, like proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules.[15][16] Typical techniques for these are either using stubs/drivers or execution from a debugger environment.[16]\n\nStatic testing involves verification, whereas dynamic testing also involves validation.[16]\n\nPassive testing means verifying the system behavior without any interaction with the software product. Contrary to active testing, testers do not provide any test data but look at system logs and traces. They mine for patterns and specific behavior in order to make some kind of decisions.[17] This is related to offline runtime verification and log analysis.A study conducted by NIST in 2002 reports that software bugs cost the U.S. economy $59.5 billion annually. More than a third of this cost could be avoided, if better software testing was performed.[10][dubious – discuss]\n\nOutsourcing software testing because of costs is very common, with China, the Philippines, and India, being preferred destinations.\nSoftware testing can be done by dedicated software testers; until the 1980s, the term \"software tester\" was used generally, but later it was also seen as a separate profession. Regarding the periods and the different goals in software testing,[12] different roles have been established, such as test manager, test lead, test analyst, test designer, tester, automation developer, and test administrator. Software testing can also be performed by non-dedicated software testers.[13]\n\n\n\n', 'https://www.theiceway.com/hubfs/Why%20is%20Software%20Testing%20So%20Important.jpg', 'Make bug free softwares'),
(5, 'Cybersecurity', 'Computer security, cyber security, digital security or information technology security (IT security) is the protection of computer systems and networks from attacks by malicious actors that may result in unauthorized information disclosure, theft of, or damage to hardware, software, or data, as well as from the disruption or misdirection of the services they provide.[1][2]\n\nThe field is significant due to the expanded reliance on computer systems, the Internet,[3] and wireless network standards such as Bluetooth and Wi-Fi. Also, due to the growth of smart devices, including smartphones, televisions, and the various devices that constitute the Internet of things (IoT). Cybersecurity is one of the most significant challenges of the contemporary world, due to both the complexity of information systems and the societies they support. Security is of especially high importance for systems that govern large-scale systems with far-reaching physical effects, such as power distribution, elections, and financeSince the Internet\'s arrival and with the digital transformation initiated in recent years, the notion of cybersecurity has become a familiar subject in both our professional and personal lives. Cybersecurity and cyber threats have been consistently present for the last 60 years of technological change. In the 1970s and 1980s, computer security was mainly limited to academia until the conception of the Internet, where, with increased connectivity, computer viruses and network intrusions began to take off. After the spread of viruses in the 1990s, the 2000s marked the institutionalization of organized attacks such as Distributed Denial of Service.[6] This led to the formalization of cybersecurity as a professional discipline.[7]\n\nThe April 1967 session organized by Willis Ware at the Spring Joint Computer Conference, and the later publication of the Ware Report, were foundational moments in the history of the field of computer security.[8] Ware\'s work straddled the intersection of material, cultural, political, and social concerns.[8]\n\nA 1977 NIST publication[9] introduced the CIA triad of confidentiality, integrity, and availability as a clear and simple way to describe key security goals.[10] While still relevant, many more elaborate frameworks have since been proposed.[11][12]\n\nHowever, in the 1970s and 1980s, there were no grave computer threats because computers and the internet were still developing, and security threats were easily identifiable. More often, threats came from malicious insiders who gained unauthorized access to sensitive documents and files. Although malware and network breaches existed during the early years, they did not use them for financial gain. By the second half of the 1970s, established computer firms like IBM started offering commercial access control systems and computer security software products.[13]\n\nOne of the earliest examples of an attack on a computer network was the computer worm Creeper written by Bob Thomas at BBN, which propagated through the ARPANET in 1971. The program was purely experimental in nature and carried no malicious payload. A later program, Reaper, was created by Ray Tomlinson in 1972 and used to destroy Creeper.\n\nBetween September 1986 and June 1987, a group of German hackers performed the first documented case of cyber espionage. The group hacked into American defense contractors, universities, and military base networks and sold gathered information to the Soviet KGB. The group was led by Markus Hess, who was arrested on 29 June 1987. He was convicted of espionage (along with two co-conspirators) on 15 Feb 1990.\n\nIn 1988, one of the first computer worms, called the Morris worm, was distributed via the Internet. It gained significant mainstream media attention.\n\nIn 1993, Netscape started developing the protocol SSL, shortly after the National Center for Supercomputing Applications (NCSA) launched Mosaic 1.0, the first web browser, in 1993. Netscape had SSL version 1.0 ready in 1994, but it was never released to the public due to many serious security vulnerabilities. These weaknesses included replay attacks and a vulnerability that allowed hackers to alter unencrypted communications sent by users. However, in February 1995, Netscape launched Version 2.0.\n\nThe National Security Agency (NSA) is responsible for the protection of U.S. information systems and also for collecting foreign intelligence.[14]\n\nThe agency analyzes commonly used software and system configurations to find security flaws, which it can use for offensive purposes against competitors of the United States.[15]\n\nNSA contractors created and sold click-and-shoot attack tools to US agencies and close allies, but eventually, the tools made their way to foreign adversaries.[citation needed] In 2016, NSAs own hacking tools were hacked, and they have been used by Russia and North Korea.[citation needed] NSA\'s employees and contractors have been recruited at high salaries by adversaries, anxious to compete in cyberwarfare.[citation needed] In 2007, the United States and Israel began exploiting security flaws in the Microsoft Windows operating system to attack and damage equipment used in Iran to refine nuclear materials. Iran responded by heavily investing in their own cyberwarfare capability, which it began using against the United States.[15]\n', 'https://wp.technologyreview.com/wp-content/uploads/2023/05/IBM_lock_1200.png?resize=1200,600', 'Be Safe'),
(6, 'Reality of FAANG', 'Big Tech, also known as the Tech Giants, refers to the most dominant information technology companies. The term most often refers to American technology companies, notably the five largest: Alphabet (Google), Amazon, Apple, Meta, and Microsoft.[1][2] Globally, Baidu, Alibaba, Tencent, and Xiaomi (BATX) are the Chinese equivalent of the Big Five. Big Tech can also include smaller tech companies with high valuations, such as Netflix, or non-tech companies with high-tech practices, such as the automaker Tesla.[3][4][5]\n\nThe concept of Big Tech is analogous to the consolidation of market dominance by a few companies in other market sectors, such as Goldman Sachs, Morgan Stanley, and J.P. Morgan in investment banking, the Big Three consulting firms, Big Oil, and Big Media.\nThe term \"Big Tech\" first appeared in media reports around 2013, as some economists saw signs of these companies becoming dominant with little regulation. After the late-1990s dot-com bubble wiped out most of the Nasdaq Composite stock market index, surviving technology companies expanded their market share and could no longer be considered startups. The term \"Big Tech\" became popular around 2017, following the investigation into Russian interference in the 2016 United States elections, as the role these technology companies played with access to a large amount of user data (\"big data\") and the ability to influence their users came under Congressional review. The term \"Big Tech\" is similar to how the largest oil companies were called \"Big Oil\" following the 1970s energy crisis, or the largest cigarette producers were called \"Big Tobacco\", as the United States Congress sought to regulate those industries.[6] It is also similar to how, at the turn of the 21st century, the mainstream media became dominated by a small number of corporations called \"Big Media\" or the \"Media Giants\".[7] Dominant companies like IBM and Microsoft were the 20th century precursors to Big Tech.[8]\nThe Big Four or Five tech companies are often referred to by the following names or acronyms.[42] Alphabet, the parent company of Google, may be represented by \"G\" in these acronyms, while Meta, the rebranding of Facebook, may be represented by \"F\".[43]\n\nThe acronym FANG was coined in 2013 by Jim Cramer, the television host of CNBC\'s Mad Money, to refer to Facebook, Amazon, Netflix, and Google. Cramer called these companies \"totally dominant in their markets\".[44] Cramer considered that the four companies were poised \"to really take a bite out of\" the bear market, giving double meaning to the acronym, according to Cramer\'s colleague at RealMoney.com, Bob Lang.[44][45][46] Cramer expanded FANG to FAANG in 2017, adding Apple to the other four companies due to its revenues placing it as a potential Fortune 50 company.[47]\n\nFollowing Facebook\'s name change to Meta Platforms in October 2021, as well as the 2015 creation of Google holding company Alphabet Inc., Cramer suggested replacing FAANG with MAMAA, replacing Netflix with Microsoft because Netflix\'s valuation had fallen behind the other companies. With Microsoft, these companies were each valued at over $900 billion compared to Netflix\'s $310 billion.[43] In November 2021, The Motley Fool suggested MANAMANA (a reference to the 1968 song \"Mah Nà Mah Nà\") as a replacement acronym that stands for Microsoft, Apple, Netflix, Alphabet, Meta, Amazon, Nvidia, and Adobe.[48]\n\n', 'https://media.fourdayweek.io/files/which-is-the-best-faang-company-to-work-for-2022-GxCex.jpeg', 'Why FAANG'),
(7, 'Blockchain Technology', 'A blockchain is a distributed ledger with growing lists of records (blocks) that are securely linked together via cryptographic hashes.[1][2][3][4] Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data (generally represented as a Merkle tree, where data nodes are represented by leaves). Since each block contains information about the previous block, they effectively form a chain (compare linked list data structure), with each additional block linking to the ones before it. Consequently, blockchain transactions are irreversible in that, once they are recorded, the data in any given block cannot be altered retroactively without altering all subsequent blocks.\n\nBlockchains are typically managed by a peer-to-peer (P2P) computer network for use as a public distributed ledger, where nodes collectively adhere to a consensus algorithm protocol to add and validate new transaction blocks. Although blockchain records are not unalterable, since blockchain forks are possible, blockchains may be considered secure by design and exemplify a distributed computing system with high Byzantine fault tolerance.[5]\n\nA blockchain was created by a person (or group of people) using the name (or pseudonym) Satoshi Nakamoto in 2008 to serve as the public distributed ledger for bitcoin cryptocurrency transactions, based on previous work by Stuart Haber, W. Scott Stornetta, and Dave Bayer.[6] The implementation of the blockchain within bitcoin made it the first digital currency to solve the double-spending problem without the need of a trusted authority or central server. The bitcoin design has inspired other applications[3][2] and blockchains that are readable by the public and are widely used by cryptocurrencies. The blockchain may be considered a type of payment rail.[7]\n\nPrivate blockchains have been proposed for business use. Computerworld called the marketing of such privatized blockchains without a proper security model \"snake oil\";[8] however, others have argued that permissioned blockchains, if carefully designed, may be more decentralized and therefore more secure in practice than permissionless ones.[4][9]\nCryptographer David Chaum first proposed a blockchain-like protocol in his 1982 dissertation \"Computer Systems Established, Maintained, and Trusted by Mutually Suspicious Groups.\"[10] Further work on a cryptographically secured chain of blocks was described in 1991 by Stuart Haber and W. Scott Stornetta.[4][11] They wanted to implement a system wherein document timestamps could not be tampered with. In 1992, Haber, Stornetta, and Dave Bayer incorporated Merkle trees into the design, which improved its efficiency by allowing several document certificates to be collected into one block.[4][12] Under their company Surety, their document certificate hashes have been published in The New York Times every week since 1995.[13]\n\nThe first decentralized blockchain was conceptualized by a person (or group of people) known as Satoshi Nakamoto in 2008. Nakamoto improved the design in an important way using a Hashcash-like method to timestamp blocks without requiring them to be signed by a trusted party and introducing a difficulty parameter to stabilize the rate at which blocks are added to the chain.[4] The design was implemented the following year by Nakamoto as a core component of the cryptocurrency bitcoin, where it serves as the public ledger for all transactions on the network.[3]\n\nIn August 2014, the bitcoin blockchain file size, containing records of all transactions that have occurred on the network, reached 20 GB (gigabytes).[14] In January 2015, the size had grown to almost 30 GB, and from January 2016 to January 2017, the bitcoin blockchain grew from 50 GB to 100 GB in size. The ledger size had exceeded 200 GB by early 2020.[15]\n\nThe words block and chain were used separately in Satoshi Nakamoto\'s original paper, but were eventually popularized as a single word, blockchain, by 2016.[16]\n\nAccording to Accenture, an application of the diffusion of innovations theory suggests that blockchains attained a 13.5% adoption rate within financial services in 2016, therefore reaching the early adopters\' phase.[17] Industry trade groups joined to create the Global Blockchain Forum in 2016, an initiative of the Chamber of Digital Commerce.\n\nIn May 2018, Gartner found that only 1% of CIOs indicated any kind of blockchain adoption within their organisations, and only 8% of CIOs were in the short-term \"planning or [looking at] active experimentation with blockchain\".[18] For the year 2019 Gartner reported 5% of CIOs believed blockchain technology was a \'game-changer\' for their business.[19]\n', 'https://www.cyberbahnit.com/wp-content/uploads/2017/11/blockchain.jpg', 'Emerging Tech Stack');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `blogs`
--
ALTER TABLE `blogs`
  ADD PRIMARY KEY (`Id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `blogs`
--
ALTER TABLE `blogs`
  MODIFY `Id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=12;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
